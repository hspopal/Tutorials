{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fba05d",
   "metadata": {},
   "source": [
    "# Univariate Analyses with Nilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849b531",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19dbf4",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nilearn.glm.first_level import FirstLevelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f70dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11c0b4c",
   "metadata": {},
   "source": [
    "### Define study specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 'sub-999'\n",
    "task = 'SR'\n",
    "\n",
    "# Define fmriprep template space\n",
    "template = 'MNIPediatricAsym_cohort-5_res-2'\n",
    "\n",
    "tr = 1.25  # repetition time is 1.25 seconds\n",
    "n_scans = 241  # the acquisition comprises 241 scans\n",
    "frame_times = np.arange(n_scans) * tr  # here are the corresponding frame times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d5b8ef",
   "metadata": {},
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BIDS project directory\n",
    "bids_dir = '/data/neuron/SCN/SR/'\n",
    "os.chdir(bids_dir)\n",
    "\n",
    "# Set output directory\n",
    "outp_dir = bids_dir + 'derivatives/SR_first_level/'+subj+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbacd59d",
   "metadata": {},
   "source": [
    "### Using openneuro BIDS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7a0290",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nilearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     fetch_ds000030_urls,\n\u001b[1;32m      3\u001b[0m     fetch_openneuro_dataset,\n\u001b[1;32m      4\u001b[0m     select_from_index,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m _, urls \u001b[38;5;241m=\u001b[39m fetch_ds000030_urls()\n\u001b[1;32m      9\u001b[0m exclusion_patterns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*group*\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*phenotype*\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*task-task*\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nilearn'"
     ]
    }
   ],
   "source": [
    "from nilearn.datasets import (\n",
    "    fetch_ds000030_urls,\n",
    "    fetch_openneuro_dataset,\n",
    "    select_from_index,\n",
    ")\n",
    "\n",
    "_, urls = fetch_ds000030_urls()\n",
    "\n",
    "exclusion_patterns = [\n",
    "    \"*group*\",\n",
    "    \"*phenotype*\",\n",
    "    \"*mriqc*\",\n",
    "    \"*parameter_plots*\",\n",
    "    \"*physio_plots*\",\n",
    "    \"*space-fsaverage*\",\n",
    "    \"*space-T1w*\",\n",
    "    \"*dwi*\",\n",
    "    \"*beh*\",\n",
    "    \"*task-bart*\",\n",
    "    \"*task-rest*\",\n",
    "    \"*task-scap*\",\n",
    "    \"*task-task*\",\n",
    "]\n",
    "urls = select_from_index(\n",
    "    urls, exclusion_filters=exclusion_patterns, n_subjects=2\n",
    ")\n",
    "\n",
    "data_dir, _ = fetch_openneuro_dataset(urls=urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496880d5",
   "metadata": {},
   "source": [
    "# Single Subject Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1dbb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make participant-specific directory for output if it doesn't exist\n",
    "if not os.path.exists(outp_dir):\n",
    "    os.makedirs(outp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all of the preprocessed functional runs\n",
    "func_runs = [f for f in glob.glob(bids_dir + '/derivatives/fmriprep/'+subj+'/func/'+subj+'_task-'+task+'*space-'+template+'_desc-preproc_bold.nii.gz', recursive=True)]\n",
    "func_runs.sort()\n",
    "print('Number of functional runs for '+subj+': '+str(len(func_runs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab subject's T1 as a mask to keep analysis in subject space\n",
    "subj_t1 = bids_dir+'derivatives/fmriprep/'+subj+'/anat/'+subj+'_space-'+template+'_label-GM_probseg_bin.nii.gz'\n",
    "\n",
    "# Find the task event files that are ready to become design matrices\n",
    "event_files = [f for f in glob.glob(bids_dir + '/derivatives/task_socialreward/data/SCN_'+subj[-3:]+'/'+subj+'_task-'+task+'_run-*_desc-events'+'.csv', recursive=True)]\n",
    "event_files.sort()\n",
    "\n",
    "# Set path to subject specific fmriprep output\n",
    "fmri_run_data_dir = bids_dir+'derivatives/fmriprep/'+subj+'/func/'\n",
    "\n",
    "# Set motion parameters to regress out\n",
    "motion_reg_names = ['trans_x','trans_y','trans_z','rot_x','rot_y','rot_z']\n",
    "confounds = []\n",
    "events = []\n",
    "\n",
    "# Set the relevant conditions (not contrasts)\n",
    "relv_conds = ['HighReward_Computer','HighReward_Computer-fb',\n",
    "              'HighReward_DisPeer','HighReward_DisPeer-fb',\n",
    "              'HighReward_SimPeer','HighReward_SimPeer-fb',\n",
    "              'LowReward_Computer','LowReward_Computer-fb',\n",
    "              'LowReward_DisPeer','LowReward_DisPeer-fb',\n",
    "              'LowReward_SimPeer','LowReward_SimPeer-fb']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87deff",
   "metadata": {},
   "source": [
    "## Create Design Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c0de3",
   "metadata": {},
   "source": [
    "### Import motion regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set motion parameters and input as a dataframe\n",
    "motion_reg = pd.read_csv(fmri_run_data_dir+subj+'_task-'+task+'_run-'+str(n+1)+'_desc-confounds_timeseries.tsv', sep='\\t')\n",
    "    \n",
    "# Filter for just the motion regressors specified above and add to a \n",
    "# general confounds list\n",
    "confounds.append(motion_reg[motion_reg_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b24f4",
   "metadata": {},
   "source": [
    "### Import the events file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_event_file = pd.read_csv(event_files[n])\n",
    "temp_event_file = temp_event_file[temp_event_file['trial_type'].str.contains('fixation') == False]\n",
    "events.append(temp_event_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73752c",
   "metadata": {},
   "source": [
    "## First level analysis for a single subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c963bc",
   "metadata": {},
   "source": [
    "### Set the first level model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=tr,\n",
    "                            mask_img=subj_t1,\n",
    "                            slice_time_ref=0.5,\n",
    "                            noise_model='ar1',\n",
    "                            standardize=False,\n",
    "                            hrf_model='spm',\n",
    "                            drift_model='polynomial',\n",
    "                            high_pass=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f493ffa",
   "metadata": {},
   "source": [
    "### Conduct the GLM using the functional data, event file, and the confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct the GLM using the functional data, event file, and the confounds\n",
    "fmri_glm = fmri_glm.fit(func_runs[n], events[n], confounds[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1af1db",
   "metadata": {},
   "source": [
    "### Contrasts\n",
    "Set contrasts for each condition, to make a beta map for each condition. This loop sets a column of 1s for each condition separately, so that each condition can be examined separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = {}\n",
    "for cond in relv_conds:\n",
    "    contrasts[cond] = np.zeros(n_conds)\n",
    "    cond_idx = [design_matrix.columns.to_list().index(cond)]\n",
    "    contrasts[cond][cond_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c689bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create z-scored beta maps contrasts\n",
    "for n_cont in range(len(contrasts)):\n",
    "    cont_name = list(contrasts.keys())[n_cont]\n",
    "    z_map = fmri_glm.compute_contrast(contrasts[cont_name], output_type='z_score')\n",
    "    \n",
    "    z_map.to_filename(os.path.join(outp_dir,'zmap_'+task+'_'+cont_name+'_run-'+str(n+1)+'.nii.gz'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8090f0",
   "metadata": {},
   "source": [
    "## Loop through all functional runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2702508",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrices = []\n",
    "for n in range(len(func_runs)):\n",
    "    # Set motion parameters and input as a dataframe\n",
    "    motion_reg = pd.read_csv(fmri_run_data_dir+subj+'_task-'+task+'_run-'+str(n+1)+'_desc-confounds_timeseries.tsv', sep='\\t')\n",
    "    \n",
    "    # Filter for just the motion regressors specified above and add to a \n",
    "    # general confounds list\n",
    "    confounds.append(motion_reg[motion_reg_names])\n",
    "\n",
    "    # Import the event file as a dataframe                 \n",
    "    temp_event_file = pd.read_csv(event_files[n])\n",
    "    temp_event_file = temp_event_file[temp_event_file['trial_type'].str.contains('fixation') == False]\n",
    "    events.append(temp_event_file)\n",
    "    \n",
    "    # Set the first level model parameters\n",
    "    fmri_glm = FirstLevelModel(t_r=tr,\n",
    "                               mask_img=subj_t1,\n",
    "                               slice_time_ref=0.5,\n",
    "                               noise_model='ar1',\n",
    "                               standardize=False,\n",
    "                               hrf_model='spm',\n",
    "                               drift_model='polynomial',\n",
    "                               high_pass=0.01)\n",
    "\n",
    "    # Conduct the GLM using the functional data, event file, and the confounds\n",
    "    fmri_glm = fmri_glm.fit(func_runs[n], events[n], confounds[n])\n",
    "\n",
    "    # Specify the design matrix to pull conditions and contrasts later\n",
    "    design_matrix = fmri_glm.design_matrices_[0]\n",
    "    \n",
    "    # Find the total number of conditions in the design matrix\n",
    "    n_conds = len(design_matrix.columns)\n",
    "\n",
    "\n",
    "    # Set contrasts for each condition, to make a beta map for each condition\n",
    "    # This loop sets a column of 1s for each condition separately, so that\n",
    "    # each condition can be examined separately \n",
    "    contrasts = {}\n",
    "    for cond in relv_conds:\n",
    "        contrasts[cond] = np.zeros(n_conds)\n",
    "        cond_idx = [design_matrix.columns.to_list().index(cond)]\n",
    "        contrasts[cond][cond_idx] = 1\n",
    "\n",
    "\n",
    "    # Create z-scored beta maps contrasts\n",
    "    for n_cont in range(len(contrasts)):\n",
    "        cont_name = list(contrasts.keys())[n_cont]\n",
    "        z_map = fmri_glm.compute_contrast(contrasts[cont_name], output_type='z_score')\n",
    "    \n",
    "        z_map.to_filename(os.path.join(outp_dir,'zmap_'+task+'_'+cont_name+'_run-'+str(n+1)+'.nii.gz'))\n",
    "    \n",
    "    # Export design matrix image\n",
    "    \n",
    "    \n",
    "    # Save design matrix for between run analysis\n",
    "    design_matrices.append(design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cc18c",
   "metadata": {},
   "source": [
    "## Compute contrasts across all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92398b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=tr,\n",
    "                           mask_img=subj_t1,\n",
    "                           slice_time_ref=0.5,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='polynomial',\n",
    "                           high_pass=0.01)\n",
    "\n",
    "fmri_glm = fmri_glm.fit(func_runs, design_matrices=design_matrices)\n",
    "\n",
    "for n_cont in range(len(contrasts)):\n",
    "    cont_name = list(contrasts.keys())[n_cont]\n",
    "    z_map = fmri_glm.compute_contrast(contrasts[cont_name], output_type='z_score')\n",
    "\n",
    "    z_map.to_filename(os.path.join(outp_dir,'zmap_'+task+'_'+cont_name+'_run-all.nii.gz'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195a9cd",
   "metadata": {},
   "source": [
    "## Create Specific Contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5042495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of conditions that will be tested against each other\n",
    "# The index of each list will be the contrast (e.g. cond_a_list[0] > cond_b_list[0])\n",
    "cond_a_list = ['HighReward_SimPeer-fb', 'HighReward_SimPeer-fb', 'HighReward_SimPeer', 'HighReward_SimPeer']\n",
    "cond_b_list = ['HighReward_DisPeer-fb', 'HighReward_Computer-fb', 'HighReward_DisPeer', 'HighReward_Computer']\n",
    "contrasts_df = pd.DataFrame(list(zip(cond_a_list, cond_b_list)), \n",
    "                            columns=['cond_a','cond_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that will store the contrast arrays\n",
    "contrasts_bw_conds = {}\n",
    "\n",
    "dm_cols = list(design_matrices[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through and fill in 1s and 0s for contrasts\n",
    "for n in range(len(contrasts_df)):\n",
    "    # Find the condition names to be contrasted\n",
    "    cond_a = contrasts_df.loc[n,'cond_a']\n",
    "    cond_b = contrasts_df.loc[n,'cond_b']\n",
    "    \n",
    "    # Create an array of zeros\n",
    "    contrasts_bw_conds[cond_a+'_V_'+cond_b] = np.zeros(len(dm_cols))\n",
    "    \n",
    "    # Find the index of each condtion as defined before\n",
    "    temp_idx_a = dm_cols.index(cond_a)\n",
    "    temp_idx_b = dm_cols.index(cond_b)\n",
    "    \n",
    "    # Fill the exact condition index in the contrast array with a 1 or -1\n",
    "    contrasts_bw_conds[cond_a+'_V_'+cond_b][temp_idx_a] = 1\n",
    "    contrasts_bw_conds[cond_a+'_V_'+cond_b][temp_idx_b] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contrast maps\n",
    "for n_cont in range(len(contrasts_bw_conds)):\n",
    "    cont_name = list(contrasts_bw_conds.keys())[n_cont]\n",
    "    z_map = fmri_glm.compute_contrast(contrasts_bw_conds[cont_name], output_type='z_score')\n",
    "\n",
    "    z_map.to_filename(os.path.join(outp_dir,'zmap_'+task+'_'+cont_name+'_run-all.nii.gz'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef770ea7",
   "metadata": {},
   "source": [
    "***\n",
    "# Second Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87388d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
